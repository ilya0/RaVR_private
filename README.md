# rAvR

rAvR is a augmented reality application for djs and patrons to interact and create a completely unique experience.

rAvR is a one of a kind music application pushing music performers to think about music experiences in a completely new and different way. rAvR focuses on creating a new visual, sonic and interactive experience between the music fans and performers, rather having a one sided musical performance. 

No longer are music shows a one way experience where djs play to a crowd, fans now can actively participate in selecting music, selecting tracks and seeing visuals that could never be physically possible.

Fans can interact with music in various ways. For example, by selecting various blocks and elements on the blocks, which the dj has created and assigned to tacks, fans can hear different basslines, vocals or samples. 

Also, performers can also assign various spaces and locations of a venue with dynamic sounds or visuals. By moving around a venue, fans can physically and mix in music or samples into the currently playing tracks by the performers and hear it live in their headsets.



## Inspiration

As a group of musicians, graphics designers and computer scientists, we have been seeking a new way to experience music and music events with live performers in a new an innovative way. 

rAvR came to us, after thinking about how music, music performance and the show experience could be differently thought about in the context of using AR or VR. We also wanted a new lay of interactivity between the performer and fans, in a way that could never been possible without AR or VR.



## What it does



rAvR now allows musicians not only to be creative, musically but allows djs and musicians to curate an experience by allowing the fans to participate in the actual music creation. 

Djs can now play music and also create innovative ways to allow fans and patrons to participate in the music show by selecting tracks, play samples and interact with a dynamic environments.

## How we built it

During this project we used, Unity, Microsoft Hololens and C# to build the various elements in virtual environment. We used the  Maya, Blender, Cinema4d, Adobe After Effects for the creation of the various graphics and animations in the environments. And we used Ableton Traktor, and Fruity Loops Studio 12 to edit and create music as well as gain inspiration for dj controls and effects.


## Challenges we ran into

The first challenge what considering what environment and device to build on. We initially wanted to build on a VR platform but quickly realized that using and AR setup would allow patrons and musicians to experience the music shows in realtime, in real life with added lay of experience.

Another challenge we ran into, was creating a networked solution for the hololenses. There was loose documentation for networking of the hololenses and so creating custom code to show all the objects in all the hololenses in real time, was quite challenging. 

In graphics, understanding how to create actionable content, while creating a interesting environment, ease of use and understandable actions was a challenge we had to over come.

During the production of the sound samples, one major issue we ran into was how the software FL Studio 12 would export .mp3 files with a few milliseconds of empty sound space at the head and tail end of the sample track as well as changing the length of the actual audio in the clip thus rendering it impossible to have loops in the correct time signature so we had to scrap all the samples we had made and make new samples in a .wav format.


The first challenge what considering what environment and device to build on. We initially wanted to build on a VR platform but quickly realized that using and AR setup would allow patrons and musicians to experience the music shows in realtime, in real life with added lay of experience.

Another challenge we ran into, was creating a networked solution for the hololenses. There was loose documentation for networking of the hololenses and so creating custom code to show all the objects in all the hololenses in real time, was quite challenging. 


- The main challenge with this project was handling the hololens platform and since I have never interacted with a Hololens device before it took me a while to learn the inputs and I wasnâ€™t able to figure out how to network two devices with each other, but I did get very close!

## Accomplishments that we're proud of

Being able to go from absolute zero on skill with VR/AR and Unity to being able to make small edits to projects in Unity and understand the workflow involved with making any game or realtime application, not nessicerily in AR/VR.


None of our team members had experience with the hololens before the hackathon started.  Our software engineeers are high school students, 16 and 14 years old.  

I am actually proud that I was able to figure out how to use the hololens and that I got extremely close to figuring out the networking aspect of it. The fact that I got really close is an accomplishment because I had figured out a lot in a minimal amount of time.

## What we learned

Spacial understanding.  Augmented Reality development hurdles including anchor points and user interaction with gameObjects in AR.  Optimization within Hololens.  Time management.


## What we learned

Having absolutely no experience with VR let alone AR, by working on this project I had a whole change in perspective of how lines of code on a screen can be layered on corporeal entities to bring the digital and analog worlds together.



## What's next for rAvR

* Network Connectivity, one or more headsets connecting to a base station
* Graphical optimization for various delivery outlets.  Refine the networking to allow a seemless mutliplayer experience.
* Optimizing code and graphics for hololens performance
* Creating a google carbord version for those that don't own hololens
* Graphics upgrades
* Show effects, light shows, virtual cannons, lazers
* Djs controls

